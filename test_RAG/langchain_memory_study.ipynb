{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c413022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5614377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd3fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0336fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ed1923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e14ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8b6f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is Andrew.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa84c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 초기화\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a5d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df67f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a9efc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55bb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c480b337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2b3f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fe11a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5010cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0729b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b74b42",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e53f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2449dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5dc29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c366a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55e7c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/lib/python3.11/site-packages (0.1.14)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-macosx_14_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (1.109.1)\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (3.11.16)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.11/site-packages (from tiktoken) (2024.11.6)\n",
      "Downloading faiss_cpu-1.13.0-cp39-abi3-macosx_14_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain faiss-cpu openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679f7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3091904",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"Please list all your shirts with sun protection \\\n",
    "in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba399d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319cd1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, model='gpt-4o-mini')\n",
    "response = index.query(query, llm=llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b333ec75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " \n",
       "\n",
       "| Name                                      | Description                                                                                                           |\n",
       "|-------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt   | Lightest hot-weather shirt with UPF 50+ sun protection, relaxed fit, wrinkle-resistant, and features cape venting.    |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve    | Ultracomfortable shirt with UPF 50+ sun protection, designed for fishing, quick-drying, and features cape venting.     |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve      | Lightweight sun-protection shirt with UPF 50+, relaxed fit, wrinkle-resistant, and features cape venting.              |\n",
       "| Sun Shield Shirt                          | High-performance sun shirt with UPF 50+, slightly fitted, moisture-wicking, and abrasion resistant for durability.      |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ed64f",
   "metadata": {},
   "source": [
    "## LLM's on Documents\n",
    "우리는 언어 모델을 사용하고 이를 많은 문서와 결합하여 활용하고 싶습니다. 하지만 중요한 문제가 있습니다. 언어 모델은 한 번에 수천 단어만 검사할 수 있습니다. 그렇다면 매우 큰 문서가 있는 경우 언어 모델이 거기에 있는 모든 것에 대한 질문에 답하도록 하려면 어떻게 해야 할까요? 여기서는 임베딩(Embedding) 과 벡터 저장소(Vector Store) 가 작동합니다. 먼저 임베딩(Embedding)에 대해 알아보겠습니다.\n",
    "\n",
    "## Embeddings\n",
    "임베딩은 텍스트 조각에 대한 숫자 표현을 만듭니다. 이 숫자 표현은 지나간 텍스트 조각의 의미를 포착합니다. 유사한 내용을 가진 텍스트 조각은 유사한 벡터를 갖습니다. 이를 통해 벡터 공간의 텍스트 조각을 비교할 수 있습니다.\n",
    "\n",
    "아래 예에서는 세 개의 문장이 있음을 알 수 있습니다. 처음 두 개는 애완동물에 관한 것이고, 세 번째는 자동차에 관한 것입니다. 숫자 공간의 표현을 보면 애완동물에 관한 문장에 해당하는 텍스트 조각의 두 벡터를 비교할 때 매우 유사하다는 것을 알 수 있습니다. 반면에 자동차에 대해 이야기하는 것과 비교하면 전혀 유사하지 않습니다. 이를 통해 어떤 텍스트 조각이 서로 유사한지 쉽게 파악할 수 있으며, 질문에 답하기 위해 언어 모델에 전달할 때 어떤 텍스트 조각을 포함할지 생각할 때 매우 유용합니다.\n",
    "\n",
    "## Vector Database\n",
    "우리가 다룰 다음 구성 요소는 벡터 데이터베이스입니다. 벡터 데이터베이스는 이전 단계에서 생성한 이러한 벡터 표현을 저장하는 방법입니다. 이 벡터 데이터베이스를 만드는 방법은 들어오는 문서에서 나오는 텍스트 덩어리로 채우는 것입니다. 큰 문서가 수신되면 먼저 이를 더 작은 덩어리로 나눕니다. 이는 원본 문서보다 작은 텍스트 조각을 만드는 데 도움이 되며, 전체 문서를 언어 모델에 전달할 수 없기 때문에 유용합니다. 그래서 우리는 이러한 작은 덩어리를 만들고 이를 벡터 데이터베이스에 저장하기 위해서 각 청크에 대한 임베딩을 생성합니다.\n",
    "\n",
    "인덱스를 생성하면 어떤 일이 발생합니까? 이제 이 인덱스가 있으므로 런타임 중에 이를 사용하여 들어오는 쿼리와 가장 관련성이 높은 텍스트 조각을 찾을 수 있습니다. 쿼리가 들어오면 먼저 해당 쿼리에 대한 임베딩을 만듭니다. 그런 다음 이를 벡터 데이터베이스의 모든 벡터와 비교하고 가장 유사한 n개를 선택합니다. 그런 다음 이러한 내용이 반환되고 프롬프트의 내용을 언어 모델에 전달하여 최종 답변을 얻을 수 있습니다.\n",
    "\n",
    "### Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc3c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ccc181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dfe8354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df1a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff608e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Jun\")\n",
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f43b56a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.023703170548746183, -0.0035304643096240964, -0.0050888707952036856, -0.012524971531567659, -0.0060989492496729796]\n"
     ]
    }
   ],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4574e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a4e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4786e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = db.similarity_search(query)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0448b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 374\\nname: Men's Plaid Tropic Shirt, Short-Sleeve\\ndescription: Our Ultracomfortable sun protection is rated to UPF 50+, helping you stay cool and dry. Originally designed for fishing, this lightest hot-weather shirt offers UPF 50+ coverage and is great for extended travel. SunSmart technology blocks 98% of the sun's harmful UV rays, while the high-performance fabric is wrinkle-free and quickly evaporates perspiration. Made with 52% polyester and 48% nylon, this shirt is machine washable and dryable. Additional features include front and back cape venting, two front bellows pockets and an imported design. With UPF 50+ coverage, you can limit sun exposure and feel secure with the highest rated sun protection available.\", metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 374})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc8442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "874c4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55826ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdocs = \"\".join([docs[i].page_content + \"/n======/n/n\" for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc8fe477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': 255\\nname: Sun Shield Shirt by\\ndescription: \"Block the sun, not the fun – our high-performance sun shirt is guaranteed to protect from harmful UV rays. \\n\\nSize & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\\n\\nFabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\n\\nAdditional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\\n\\nSun Protection That Won\\'t Wear Off\\nOur high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant./n======/n/n: 374\\nname: Men\\'s Plaid Tropic Shirt, Short-Sleeve\\ndescription: Our Ultracomfortable sun protection is rated to UPF 50+, helping you stay cool and dry. Originally designed for fishing, this lightest hot-weather shirt offers UPF 50+ coverage and is great for extended travel. SunSmart technology blocks 98% of the sun\\'s harmful UV rays, while the high-performance fabric is wrinkle-free and quickly evaporates perspiration. Made with 52% polyester and 48% nylon, this shirt is machine washable and dryable. Additional features include front and back cape venting, two front bellows pockets and an imported design. With UPF 50+ coverage, you can limit sun exposure and feel secure with the highest rated sun protection available./n======/n/n: 535\\nname: Men\\'s TropicVibe Shirt, Short-Sleeve\\ndescription: This Men’s sun-protection shirt with built-in UPF 50+ has the lightweight feel you want and the coverage you need when the air is hot and the UV rays are strong. Size & Fit: Traditional Fit: Relaxed through the chest, sleeve and waist. Fabric & Care: Shell: 71% Nylon, 29% Polyester. Lining: 100% Polyester knit mesh. UPF 50+ rated – the highest rated sun protection possible. Machine wash and dry. Additional Features: Wrinkle resistant. Front and back cape venting lets in cool breezes. Two front bellows pockets. Imported.\\n\\nSun Protection That Won\\'t Wear Off: Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays./n======/n/n: 618\\nname: Men\\'s Tropical Plaid Short-Sleeve Shirt\\ndescription: Our lightest hot-weather shirt is rated UPF 50+ for superior protection from the sun\\'s UV rays. With a traditional fit that is relaxed through the chest, sleeve, and waist, this fabric is made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets, this shirt is imported and provides the highest rated sun protection possible. \\n\\nSun Protection That Won\\'t Wear Off. Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays./n======/n/n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd5070ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"document: {qdocs} /n Question: From the above document, please list all your \\\n",
    "shirts name correctly with sun protection in a table in markdown and summarize each one.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b3f825d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Shirt Name | Summary |\n",
       "|-----------|---------|\n",
       "| Sun Shield Tee | Lightweight and breathable shirt with UPF 50+ sun protection, perfect for outdoor activities |\n",
       "| Solar Performance Long Sleeve | Long sleeve shirt with moisture-wicking fabric and UPF 50+ sun protection, great for all-day sun exposure |\n",
       "| Sun Protection Hoodie | Hoodie with built-in sun protection, ideal for cooler days when you still need sun protection |\n",
       "| UV Sun Protection Shirt | Stylish shirt with UPF 30+ sun protection, suitable for everyday wear in the sun |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3fec2",
   "metadata": {},
   "source": [
    "## Using LangChain\n",
    "그렇다면 이를 어떻게 사용하여 문서에 대한 질문에 답할 수 있을까요? 먼저 이 벡터 저장소에서 검색기(retriever)를 만들어야 합니다. 검색기(retriever)는 쿼리를 받아 문서를 반환하는 모든 메서드로 뒷받침될 수 있는 일반 인터페이스입니다. 벡터 스토어와 임베딩은 그렇게 하기 위한 방법 중 하나입니다. 물론 덜 발전된 방법도 있고 좀 더 발전된 방법도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e742dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lanchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt\n",
    "from langchain import hub\n",
    "\n",
    "# Loads the latest version\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")\n",
    "\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs={\"verbose\": True, \"prompt\": prompt},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9869bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baef5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf43634",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9089f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
